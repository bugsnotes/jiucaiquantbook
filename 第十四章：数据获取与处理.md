# ç¬¬åå››ç« ï¼šæ•°æ®è·å–ä¸å¤„ç†

**é€‚åˆäººç¾¤**: æœ‰PythonåŸºç¡€ï¼Œæƒ³è¦è·å–å’Œå¤„ç†è‚¡ç¥¨æ•°æ®çš„æŠ•èµ„è€…
**å­¦ä¹ æ—¶é—´**: 3-4å¤©
**ç›®æ ‡**: æŒæ¡ä¸»æµæ•°æ®æºçš„ä½¿ç”¨ï¼Œèƒ½å¤Ÿè·å–ã€æ¸…æ´—ã€å­˜å‚¨è‚¡ç¥¨æ•°æ®

---

> ğŸ’¡ **æ•°æ®æ˜¯é‡åŒ–äº¤æ˜“çš„åŸºç¡€**ï¼šæ²¡æœ‰æ•°æ®ï¼Œå†å¥½çš„ç­–ç•¥ä¹Ÿåªæ˜¯çº¸ä¸Šè°ˆå…µã€‚æœ¬ç« æ•™ä½ å¦‚ä½•è·å–é«˜è´¨é‡çš„è‚¡ç¥¨æ•°æ®ï¼Œå¹¶è¿›è¡Œä¸“ä¸šçš„å¤„ç†ã€‚

---

## 14.1 æ•°æ®è·å–å®æˆ˜

### æ•°æ®æºå…¨æ™¯å›¾

**å›½å†…ä¸»æµæ•°æ®æºå¯¹æ¯”**ï¼š

| æ•°æ®æº | ç±»å‹ | æ•°æ®è´¨é‡ | ä»·æ ¼ | é€‚ç”¨åœºæ™¯ |
|--------|------|---------|------|---------|
| **Tushare Pro** | å…è´¹+ä»˜è´¹ | ä¸­ç­‰ | ç§¯åˆ†åˆ¶ | ä¸ªäººå­¦ä¹ ã€å°è§„æ¨¡å›æµ‹ |
| **9dbæ•°æ®å¹³å°** â­ | ä»˜è´¹ | é«˜ | æŒ‰éœ€ä»˜è´¹ | ä¸“ä¸šå›æµ‹ã€å®ç›˜äº¤æ˜“ |
| **AKShare** | å…è´¹ | ä¸­ç­‰ | å…è´¹ | å¿«é€ŸéªŒè¯ã€å­¦ä¹  |
| **Wind** | ä»˜è´¹ | æœ€é«˜ | è´µ | æœºæ„ã€ä¸“ä¸šç ”ç©¶ |
| **Choice** | ä»˜è´¹ | é«˜ | è¾ƒè´µ | æœºæ„ã€ä¸“ä¸šç ”ç©¶ |

**æœ¬ç« é‡ç‚¹**ï¼š
- âœ… Tushare Proï¼ˆå…è´¹ï¼Œé€‚åˆå…¥é—¨ï¼‰
- â­ 9dbæ•°æ®å¹³å°ï¼ˆé‡ç‚¹æ¨èï¼Œé«˜è´¨é‡ï¼‰
- âœ… AKShareï¼ˆå®Œå…¨å…è´¹ï¼Œå¿«é€Ÿä¸Šæ‰‹ï¼‰

---

### Tushare Proæ•°æ®è·å–

#### 1. æ³¨å†Œä¸Tokenè·å–

**æ­¥éª¤**ï¼š

```
1. è®¿é—®ï¼šhttps://tushare.pro/register
2. æ³¨å†Œè´¦å·ï¼ˆæ‰‹æœºå·å³å¯ï¼‰
3. ç™»å½•åï¼Œè¿›å…¥"ä¸ªäººä¸­å¿ƒ" â†’ "æ¥å£TOKEN"
4. å¤åˆ¶ä½ çš„ä¸“å±Token
```

**ç§¯åˆ†è¯´æ˜**ï¼š

```
Tushareé‡‡ç”¨ç§¯åˆ†åˆ¶ï¼š
- æ³¨å†Œé€120ç§¯åˆ†
- æ¯æ—¥ç­¾åˆ°+1ç§¯åˆ†
- é‚€è¯·å¥½å‹+100ç§¯åˆ†
- å……å€¼è·å¾—ç§¯åˆ†

ç§¯åˆ†ç”¨é€”ï¼š
- ä¸åŒæ¥å£éœ€è¦ä¸åŒç§¯åˆ†æƒé™
- æ—¥çº¿æ•°æ®ï¼š120ç§¯åˆ†å³å¯
- åˆ†é’Ÿæ•°æ®ï¼šéœ€è¦2000+ç§¯åˆ†
- è´¢åŠ¡æ•°æ®ï¼šéœ€è¦æ›´é«˜ç§¯åˆ†
```

#### 2. å®‰è£…ä¸é…ç½®

```bash
# å®‰è£…Tushare
pip install tushare

# å¦‚æœå®‰è£…æ…¢ï¼Œä½¿ç”¨å›½å†…é•œåƒ
pip install tushare -i https://pypi.tuna.tsinghua.edu.cn/simple
```

**åŸºæœ¬ä½¿ç”¨**ï¼š

```python
import tushare as ts

# è®¾ç½®Tokenï¼ˆåªéœ€è®¾ç½®ä¸€æ¬¡ï¼‰
ts.set_token('ä½ çš„Token')

# åˆå§‹åŒ–proæ¥å£
pro = ts.pro_api()

# æµ‹è¯•ï¼šè·å–è´µå·èŒ…å°çš„æ—¥çº¿æ•°æ®
df = pro.daily(ts_code='600519.SH', start_date='20240101', end_date='20240131')
print(df.head())
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
    ts_code trade_date   open   high    low  close  ...
0  600519.SH   20240131  1680.0 1720.5 1675.0 1710.2  ...
1  600519.SH   20240130  1670.5 1685.0 1665.0 1680.0  ...
```

#### 3. å¸¸ç”¨æ•°æ®æ¥å£

**ï¼ˆ1ï¼‰è‚¡ç¥¨æ—¥çº¿è¡Œæƒ…**ï¼š

```python
import tushare as ts
import pandas as pd

pro = ts.pro_api('ä½ çš„Token')

# è·å–å•åªè‚¡ç¥¨æ—¥çº¿æ•°æ®
df = pro.daily(
    ts_code='600519.SH',      # è‚¡ç¥¨ä»£ç 
    start_date='20240101',    # å¼€å§‹æ—¥æœŸ
    end_date='20240131'       # ç»“æŸæ—¥æœŸ
)

# æ•°æ®åŒ…å«ï¼š
# ts_code: è‚¡ç¥¨ä»£ç 
# trade_date: äº¤æ˜“æ—¥æœŸ
# open: å¼€ç›˜ä»·
# high: æœ€é«˜ä»·
# low: æœ€ä½ä»·
# close: æ”¶ç›˜ä»·
# pre_close: å‰æ”¶ç›˜ä»·
# change: æ¶¨è·Œé¢
# pct_chg: æ¶¨è·Œå¹…(%)
# vol: æˆäº¤é‡(æ‰‹)
# amount: æˆäº¤é¢(åƒå…ƒ)

print(df)
```

**ï¼ˆ2ï¼‰è·å–è‚¡ç¥¨åˆ—è¡¨**ï¼š

```python
# è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨åˆ—è¡¨
stock_list = pro.stock_basic(
    exchange='',
    list_status='L',  # L=ä¸Šå¸‚ D=é€€å¸‚ P=æš‚åœ
    fields='ts_code,symbol,name,area,industry,list_date'
)

print(f"å…±{len(stock_list)}åªè‚¡ç¥¨")
print(stock_list.head())

# ç­›é€‰ï¼šåªè¦ä¸»æ¿è‚¡ç¥¨
main_board = stock_list[stock_list['ts_code'].str.startswith(('600', '601', '603', '000', '001'))]
print(f"ä¸»æ¿è‚¡ç¥¨ï¼š{len(main_board)}åª")
```

**ï¼ˆ3ï¼‰è·å–æŒ‡æ•°æ•°æ®**ï¼š

```python
# è·å–ä¸Šè¯æŒ‡æ•°æ—¥çº¿æ•°æ®
index_df = pro.index_daily(
    ts_code='000001.SH',  # ä¸Šè¯æŒ‡æ•°
    start_date='20240101',
    end_date='20240131'
)

print(index_df.head())
```

**ï¼ˆ4ï¼‰æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨**ï¼š

```python
import time

def get_multiple_stocks(stock_codes, start_date, end_date):
    """æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨æ•°æ®"""
    all_data = []

    for code in stock_codes:
        try:
            df = pro.daily(
                ts_code=code,
                start_date=start_date,
                end_date=end_date
            )
            all_data.append(df)

            # é¿å…æ¥å£é™æµ
            time.sleep(0.3)  # æ¯æ¬¡è¯·æ±‚é—´éš”0.3ç§’

        except Exception as e:
            print(f"è·å–{code}å¤±è´¥: {e}")

    # åˆå¹¶æ‰€æœ‰æ•°æ®
    result = pd.concat(all_data, ignore_index=True)
    return result

# ä½¿ç”¨
stock_codes = ['600519.SH', '000858.SZ', '600036.SH']
data = get_multiple_stocks(stock_codes, '20240101', '20240131')
print(data)
```

#### 4. Tushareæ³¨æ„äº‹é¡¹

```
âš ï¸ æ¥å£é™æµ
- æ™®é€šç”¨æˆ·ï¼šæ¯åˆ†é’Ÿè°ƒç”¨æ¬¡æ•°æœ‰é™åˆ¶
- è§£å†³æ–¹æ¡ˆï¼šè¯·æ±‚ä¹‹é—´åŠ å»¶æ—¶ï¼ˆtime.sleepï¼‰

âš ï¸ ç§¯åˆ†ä¸è¶³
- æŸäº›é«˜çº§æ¥å£éœ€è¦æ›´å¤šç§¯åˆ†
- è§£å†³æ–¹æ¡ˆï¼šæ¯æ—¥ç­¾åˆ°ã€é‚€è¯·å¥½å‹ã€å……å€¼

âš ï¸ æ•°æ®å¯èƒ½æœ‰å»¶è¿Ÿ
- å…è´¹æ•°æ®å¯èƒ½å»¶è¿Ÿ1å¤©
- å®æ—¶æ•°æ®éœ€è¦æ›´é«˜ç§¯åˆ†

âœ… ä¼˜ç‚¹
- å…è´¹ä½¿ç”¨
- æ•°æ®è¦†ç›–å…¨é¢
- æ¥å£ç®€å•

âŒ ç¼ºç‚¹
- æœ‰ç§¯åˆ†é™åˆ¶
- æœ‰è°ƒç”¨é¢‘ç‡é™åˆ¶
- æ•°æ®è´¨é‡ä¸€èˆ¬
```

---

### 9dbæ•°æ®å¹³å°æ¥å…¥è¯¦è§£ â­

> ğŸ’¡ **é‡ç‚¹æ¨è**ï¼š9dbæ˜¯ä¸“ä¸šçº§é‡åŒ–æ•°æ®å¹³å°ï¼Œæ•°æ®è´¨é‡é«˜ã€è¦†ç›–å…¨é¢ï¼Œç‰¹åˆ«é€‚åˆè®¤çœŸåšé‡åŒ–äº¤æ˜“çš„æŠ•èµ„è€…ã€‚

#### 1. ä¸ºä»€ä¹ˆé€‰æ‹©9dbï¼Ÿ

**æ ¸å¿ƒä¼˜åŠ¿**ï¼š

```
âœ… æ•°æ®è´¨é‡é«˜
   - ä¸“ä¸šå›¢é˜Ÿç»´æŠ¤
   - å¤šæºäº¤å‰éªŒè¯
   - åŠæ—¶ä¿®æ­£é”™è¯¯æ•°æ®

âœ… è¦†ç›–å…¨é¢
   - è‚¡ç¥¨ã€åŸºé‡‘ã€æœŸè´§ã€å¯è½¬å€º
   - æ—¥çº¿ã€åˆ†é’Ÿçº¿ã€tickæ•°æ®
   - è´¢åŠ¡ã€ä¼°å€¼ã€è¡Œä¸šæ•°æ®

âœ… æ¥å£å‹å¥½
   - Python SDKç®€å•æ˜“ç”¨
   - æ–‡æ¡£è¯¦ç»†
   - ç¤ºä¾‹ä»£ç ä¸°å¯Œ

âœ… æ€§èƒ½ä¼˜ç§€
   - æ¥å£å“åº”å¿«
   - æ”¯æŒæ‰¹é‡æŸ¥è¯¢
   - æœ¬åœ°ç¼“å­˜æœºåˆ¶

âœ… ä¸å›æµ‹æ¡†æ¶é›†æˆ
   - å¯æ— ç¼å¯¹æ¥Qlib
   - æ”¯æŒbacktrader
   - æä¾›å®Œæ•´ä»£ç ç¤ºä¾‹
```

**é€‚ç”¨åœºæ™¯**ï¼š

```
é€‚åˆï¼š
âœ“ è®¤çœŸåšé‡åŒ–çš„ä¸ªäººæŠ•èµ„è€…
âœ“ å¯¹æ•°æ®è´¨é‡æœ‰è¦æ±‚
âœ“ éœ€è¦åˆ†é’Ÿçº§ã€Tickçº§æ•°æ®
âœ“ å®ç›˜äº¤æ˜“ä½¿ç”¨

ä¸é€‚åˆï¼š
âœ— åªæ˜¯éšä¾¿ç©ç©
âœ— å®Œå…¨é›¶é¢„ç®—
âœ— åªåšç®€å•ç­–ç•¥éªŒè¯ï¼ˆç”¨å…è´¹æ•°æ®å³å¯ï¼‰
```

#### 2. æ³¨å†Œä¸é…ç½®

**æ­¥éª¤1ï¼šæ³¨å†Œè´¦å·**

```
1. è®¿é—®ï¼šhttps://www.9db.com
2. æ³¨å†Œè´¦å·ï¼ˆæ‰‹æœºå·æˆ–é‚®ç®±ï¼‰
3. ç™»å½•åè¿›å…¥"æ•°æ®ä¸­å¿ƒ"
```

**æ­¥éª¤2ï¼šè·å–API Key**

```
1. è¿›å…¥"ä¸ªäººä¸­å¿ƒ" â†’ "APIç®¡ç†"
2. ç”ŸæˆAPI Keyå’ŒSecret
3. ä¿å­˜å¥½ï¼ˆåé¢ä¼šç”¨åˆ°ï¼‰
```

**æ­¥éª¤3ï¼šé€‰æ‹©å¥—é¤**

```
9dbæä¾›å¤šç§å¥—é¤ï¼š
- åŸºç¡€ç‰ˆï¼šæ—¥çº¿æ•°æ®ï¼Œé€‚åˆå­¦ä¹ 
- ä¸“ä¸šç‰ˆï¼šæ—¥çº¿+åˆ†é’Ÿæ•°æ®ï¼Œé€‚åˆå›æµ‹
- æ——èˆ°ç‰ˆï¼šå…¨éƒ¨æ•°æ®ï¼Œé€‚åˆå®ç›˜

å»ºè®®ï¼š
- åˆå­¦è€…ï¼šå…ˆè¯•ç”¨åŸºç¡€ç‰ˆ
- è®¤çœŸåšé‡åŒ–ï¼šé€‰æ‹©ä¸“ä¸šç‰ˆæˆ–æ——èˆ°ç‰ˆ
```

#### 3. SDKå®‰è£…ä¸é…ç½®

**å®‰è£…SDK**ï¼š

```bash
# ä½¿ç”¨pipå®‰è£…
pip install ninedb-sdk

# æˆ–ä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿ
pip install ninedb-sdk -i https://pypi.tuna.tsinghua.edu.cn/simple
```

**é…ç½®è®¤è¯**ï¼š

```python
from ninedb import NineDB

# åˆå§‹åŒ–ï¼ˆæ–¹æ³•1ï¼šç›´æ¥ä¼ å…¥ï¼‰
db = NineDB(
    api_key='ä½ çš„API_KEY',
    api_secret='ä½ çš„API_SECRET'
)

# åˆå§‹åŒ–ï¼ˆæ–¹æ³•2ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
# åˆ›å»ºé…ç½®æ–‡ä»¶ ~/.ninedb/config.json
# {
#     "api_key": "ä½ çš„API_KEY",
#     "api_secret": "ä½ çš„API_SECRET"
# }

db = NineDB()  # è‡ªåŠ¨è¯»å–é…ç½®æ–‡ä»¶

# æµ‹è¯•è¿æ¥
print(db.test_connection())  # è¿”å›Trueè¡¨ç¤ºæˆåŠŸ
```

#### 4. æ•°æ®è·å–å®æˆ˜

**ï¼ˆ1ï¼‰è·å–è‚¡ç¥¨æ—¥çº¿æ•°æ®**ï¼š

```python
from ninedb import NineDB
import pandas as pd

# åˆå§‹åŒ–
db = NineDB(api_key='ä½ çš„key', api_secret='ä½ çš„secret')

# è·å–å•åªè‚¡ç¥¨æ—¥çº¿æ•°æ®
df = db.stock.daily(
    symbol='600519',        # è‚¡ç¥¨ä»£ç ï¼ˆä¸éœ€è¦åç¼€ï¼‰
    start_date='2024-01-01',
    end_date='2024-01-31',
    adjust='hfq'            # å¤æƒæ–¹å¼ï¼šhfq=åå¤æƒï¼Œqfq=å‰å¤æƒï¼ŒNone=ä¸å¤æƒ
)

print(df.head())
```

è¾“å‡ºï¼š

```
    symbol trade_date   open   high    low  close   volume      amount
0   600519 2024-01-02  1680.0 1720.5 1675.0 1710.2 1000000  1705500000
1   600519 2024-01-03  1710.0 1715.0 1685.0 1690.5  980000  1665690000
...
```

**ï¼ˆ2ï¼‰è·å–åˆ†é’Ÿçº§æ•°æ®**ï¼š

```python
# è·å–5åˆ†é’ŸKçº¿
df_5min = db.stock.minutes(
    symbol='600519',
    start_date='2024-01-15',
    end_date='2024-01-15',
    freq='5min'  # 1min, 5min, 15min, 30min, 60min
)

print(df_5min.head())
```

**ï¼ˆ3ï¼‰æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨**ï¼š

```python
# æ–¹æ³•1ï¼šå¾ªç¯è·å–ï¼ˆé€‚åˆè‚¡ç¥¨æ•°é‡è¾ƒå°‘ï¼‰
stock_codes = ['600519', '000858', '600036']
all_data = []

for code in stock_codes:
    df = db.stock.daily(
        symbol=code,
        start_date='2024-01-01',
        end_date='2024-01-31'
    )
    all_data.append(df)

result = pd.concat(all_data, ignore_index=True)

# æ–¹æ³•2ï¼šæ‰¹é‡æ¥å£ï¼ˆæ¨èï¼Œæ•ˆç‡æ›´é«˜ï¼‰
result = db.stock.daily_batch(
    symbols=['600519', '000858', '600036'],
    start_date='2024-01-01',
    end_date='2024-01-31'
)

print(result)
```

**ï¼ˆ4ï¼‰è·å–è‚¡ç¥¨åˆ—è¡¨**ï¼š

```python
# è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨åˆ—è¡¨
stock_list = db.stock.list(
    market='A',         # A=Aè‚¡ï¼ŒHK=æ¸¯è‚¡ï¼ŒUS=ç¾è‚¡
    status='L'          # L=ä¸Šå¸‚ï¼ŒD=é€€å¸‚
)

print(f"å…±{len(stock_list)}åªè‚¡ç¥¨")
print(stock_list.head())

# ç­›é€‰ï¼šåªè¦æ²ªæ·±300æˆåˆ†è‚¡
hs300 = db.index.constituents(index_code='000300')  # æ²ªæ·±300
print(f"æ²ªæ·±300æˆåˆ†è‚¡ï¼š{len(hs300)}åª")
```

**ï¼ˆ5ï¼‰è·å–è´¢åŠ¡æ•°æ®**ï¼š

```python
# è·å–åˆ©æ¶¦è¡¨æ•°æ®
income = db.stock.income_statement(
    symbol='600519',
    start_date='2020-01-01',
    end_date='2024-01-01',
    report_type='report_date'  # report_date=æŠ¥å‘ŠæœŸï¼Œpublish_date=å…¬å‘Šæ—¥æœŸ
)

# å…³é”®å­—æ®µ
print(income[['symbol', 'report_date', 'revenue', 'net_profit', 'roe']])
```

**ï¼ˆ6ï¼‰è·å–å®æ—¶è¡Œæƒ…**ï¼š

```python
# è·å–å®æ—¶å¿«ç…§ï¼ˆç›˜ä¸­å®æ—¶æ•°æ®ï¼‰
snapshot = db.stock.realtime(
    symbols=['600519', '000858', '600036']
)

# åŒ…å«ï¼šæœ€æ–°ä»·ã€æ¶¨è·Œå¹…ã€æˆäº¤é‡ã€ä¹°å–ç›˜ç­‰
print(snapshot)
```

#### 5. å®Œæ•´ä»£ç ç¤ºä¾‹

**ç¤ºä¾‹1ï¼šè·å–å¹¶ä¿å­˜æ²ªæ·±300æˆåˆ†è‚¡æ—¥çº¿æ•°æ®**

```python
from ninedb import NineDB
import pandas as pd
from tqdm import tqdm  # è¿›åº¦æ¡
import time

# åˆå§‹åŒ–
db = NineDB(api_key='ä½ çš„key', api_secret='ä½ çš„secret')

# è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨
hs300_stocks = db.index.constituents(index_code='000300')
print(f"æ²ªæ·±300æˆåˆ†è‚¡ï¼š{len(hs300_stocks)}åª")

# æ‰¹é‡è·å–æ•°æ®
all_data = []
for stock in tqdm(hs300_stocks['symbol']):
    try:
        df = db.stock.daily(
            symbol=stock,
            start_date='2020-01-01',
            end_date='2024-12-31',
            adjust='hfq'
        )
        all_data.append(df)
        time.sleep(0.1)  # é¿å…è¯·æ±‚è¿‡å¿«

    except Exception as e:
        print(f"è·å–{stock}å¤±è´¥: {e}")

# åˆå¹¶æ•°æ®
result = pd.concat(all_data, ignore_index=True)

# ä¿å­˜åˆ°æœ¬åœ°
result.to_csv('hs300_daily_data.csv', index=False)
print(f"æ•°æ®å·²ä¿å­˜ï¼Œå…±{len(result)}æ¡è®°å½•")
```

**ç¤ºä¾‹2ï¼šè®¡ç®—æŠ€æœ¯æŒ‡æ ‡**

```python
from ninedb import NineDB
import pandas as pd
import numpy as np

# è·å–æ•°æ®
db = NineDB()
df = db.stock.daily(
    symbol='600519',
    start_date='2023-01-01',
    end_date='2024-12-31'
)

# æŒ‰æ—¥æœŸæ’åº
df = df.sort_values('trade_date').reset_index(drop=True)

# è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
def add_indicators(df):
    """æ·»åŠ å¸¸ç”¨æŠ€æœ¯æŒ‡æ ‡"""

    # ç§»åŠ¨å¹³å‡çº¿
    df['ma5'] = df['close'].rolling(window=5).mean()
    df['ma10'] = df['close'].rolling(window=10).mean()
    df['ma20'] = df['close'].rolling(window=20).mean()

    # æ”¶ç›Šç‡
    df['returns'] = df['close'].pct_change()

    # æ³¢åŠ¨ç‡ï¼ˆ20æ—¥ï¼‰
    df['volatility'] = df['returns'].rolling(window=20).std()

    # æˆäº¤é‡å‡å€¼
    df['vol_ma5'] = df['volume'].rolling(window=5).mean()

    # RSIï¼ˆç®€åŒ–ç‰ˆï¼‰
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))

    return df

# æ·»åŠ æŒ‡æ ‡
df = add_indicators(df)

# æŸ¥çœ‹ç»“æœ
print(df[['trade_date', 'close', 'ma5', 'ma20', 'rsi']].tail())

# ä¿å­˜
df.to_csv('600519_with_indicators.csv', index=False)
```

#### 6. 9dbä¸Qlibé›†æˆ

9dbæ•°æ®å¯ä»¥æ— ç¼å¯¹æ¥å¾®è½¯Qlibå¹³å°ï¼Œè¯¦è§ç¬¬19ç« ã€Šå›æµ‹æ¡†æ¶æ·±åº¦åº”ç”¨ã€‹ã€‚

**å¿«é€Ÿé¢„è§ˆ**ï¼š

```python
# 9dbæ•°æ®æ ¼å¼è½¬æ¢ä¸ºQlibæ ¼å¼
from ninedb import NineDB
from qlib.data import D

# è·å–9dbæ•°æ®
db = NineDB()
df = db.stock.daily(symbol='600519', start_date='2020-01-01', end_date='2024-12-31')

# è½¬æ¢ä¸ºQlibæ ¼å¼
qlib_data = df.rename(columns={
    'trade_date': 'datetime',
    'open': '$open',
    'high': '$high',
    'low': '$low',
    'close': '$close',
    'volume': '$volume'
})

# åœ¨Qlibä¸­ä½¿ç”¨
# è¯¦è§ç¬¬19ç« 
```

#### 7. 9dbä½¿ç”¨æ³¨æ„äº‹é¡¹

```
âœ… æœ€ä½³å®è·µ

1. ä½¿ç”¨æ‰¹é‡æ¥å£
   - ä¸€æ¬¡è¯·æ±‚å¤šåªè‚¡ç¥¨ï¼Œæ¯”å¾ªç¯å¿«å¾ˆå¤š
   - å‡å°‘è¯·æ±‚æ¬¡æ•°

2. æœ¬åœ°ç¼“å­˜
   - ä¸‹è½½åä¿å­˜åˆ°æœ¬åœ°
   - é¿å…é‡å¤è¯·æ±‚

3. åˆç†è®¾ç½®æ—¥æœŸèŒƒå›´
   - ä¸è¦ä¸€æ¬¡è¯·æ±‚å¤ªé•¿æ—¶é—´è·¨åº¦
   - å»ºè®®ï¼šæ¯æ¬¡ä¸è¶…è¿‡5å¹´

4. å¼‚å¸¸å¤„ç†
   - å¿…é¡»åŠ try-except
   - æŸäº›è‚¡ç¥¨å¯èƒ½æ²¡æœ‰æ•°æ®

âš ï¸ æ³¨æ„äº‹é¡¹

1. APIé…é¢
   - æ ¹æ®å¥—é¤æœ‰æ¯æ—¥è¯·æ±‚æ¬¡æ•°é™åˆ¶
   - åˆç†å®‰æ’æ•°æ®è·å–è®¡åˆ’

2. å¤æƒæ–¹å¼
   - å›æµ‹å¿…é¡»ç”¨åå¤æƒï¼ˆhfqï¼‰
   - å®ç›˜ç”¨ä¸å¤æƒæˆ–å‰å¤æƒ

3. æ•°æ®å»¶è¿Ÿ
   - æ—¥çº¿æ•°æ®ï¼šT+0ï¼ˆå½“å¤©æ”¶ç›˜åå³å¯è·å–ï¼‰
   - è´¢åŠ¡æ•°æ®ï¼šä»¥å…¬å‘Šæ—¥æœŸä¸ºå‡†
```

---

### AKShareä½¿ç”¨æŒ‡å—

> ğŸ’¡ **å®Œå…¨å…è´¹**ï¼šAKShareæ˜¯å¼€æºé¡¹ç›®ï¼Œæ‰€æœ‰æ•°æ®å®Œå…¨å…è´¹ï¼Œéå¸¸é€‚åˆå­¦ä¹ å’Œå¿«é€ŸéªŒè¯ç­–ç•¥ã€‚

#### 1. å®‰è£…

```bash
pip install akshare

# å¦‚æœå®‰è£…æ…¢
pip install akshare -i https://pypi.tuna.tsinghua.edu.cn/simple
```

#### 2. åŸºæœ¬ä½¿ç”¨

**è·å–è‚¡ç¥¨æ—¥çº¿æ•°æ®**ï¼š

```python
import akshare as ak

# è·å–å•åªè‚¡ç¥¨å†å²æ•°æ®
df = ak.stock_zh_a_hist(
    symbol='600519',        # è‚¡ç¥¨ä»£ç ï¼ˆä¸è¦åç¼€ï¼‰
    period='daily',         # daily, weekly, monthly
    start_date='20240101',
    end_date='20240131',
    adjust='hfq'            # åå¤æƒ
)

print(df.head())
```

**è·å–å®æ—¶è¡Œæƒ…**ï¼š

```python
# è·å–æ²ªæ·±Aè‚¡å®æ—¶è¡Œæƒ…
realtime = ak.stock_zh_a_spot_em()

# ç­›é€‰ï¼šåªçœ‹æ²ªæ·±300
hs300_realtime = realtime[realtime['ä»£ç '].isin(['600519', '000858', '600036'])]
print(hs300_realtime[['ä»£ç ', 'åç§°', 'æœ€æ–°ä»·', 'æ¶¨è·Œå¹…']])
```

**è·å–æŒ‡æ•°æ•°æ®**ï¼š

```python
# ä¸Šè¯æŒ‡æ•°å†å²æ•°æ®
sh_index = ak.stock_zh_index_daily(symbol='sh000001')
print(sh_index.tail())
```

#### 3. AKShareä¼˜ç¼ºç‚¹

```
âœ… ä¼˜ç‚¹
- å®Œå…¨å…è´¹
- æ•°æ®æºä¸°å¯Œï¼ˆè‚¡ç¥¨ã€æœŸè´§ã€æœŸæƒã€åŸºé‡‘ç­‰ï¼‰
- æ›´æ–°åŠæ—¶
- æ— éœ€æ³¨å†Œ

âŒ ç¼ºç‚¹
- æ•°æ®è´¨é‡ä¸€èˆ¬ï¼ˆå¯èƒ½æœ‰é”™è¯¯ï¼‰
- æ¥å£ä¸ç¨³å®šï¼ˆå¯èƒ½çªç„¶å˜åŒ–ï¼‰
- æ— å®˜æ–¹æŠ€æœ¯æ”¯æŒ
- ä¸é€‚åˆå®ç›˜ä½¿ç”¨

ğŸ¯ é€‚ç”¨åœºæ™¯
- å­¦ä¹ Pythoné‡åŒ–
- å¿«é€ŸéªŒè¯ç­–ç•¥æƒ³æ³•
- å°è§„æ¨¡å›æµ‹
- åšdemoæ¼”ç¤º
```

---

### å¤šæ•°æ®æºæ•´åˆæ–¹æ¡ˆ

åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œå¯ä»¥ç»“åˆå¤šä¸ªæ•°æ®æºï¼š

```python
class MultiSourceData:
    """å¤šæ•°æ®æºç®¡ç†å™¨"""

    def __init__(self):
        # åˆå§‹åŒ–å„ä¸ªæ•°æ®æº
        self.tushare = ts.pro_api('ä½ çš„token')
        self.ninedb = NineDB(api_key='ä½ çš„key', api_secret='ä½ çš„secret')

    def get_daily_data(self, symbol, start_date, end_date):
        """
        è·å–æ—¥çº¿æ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨9dbï¼Œå¤±è´¥åˆ™ç”¨tushareï¼‰
        """
        try:
            # ä¼˜å…ˆä½¿ç”¨9dbï¼ˆæ•°æ®è´¨é‡æ›´å¥½ï¼‰
            df = self.ninedb.stock.daily(
                symbol=symbol,
                start_date=start_date,
                end_date=end_date
            )
            print(f"ä»9dbè·å–{symbol}æ•°æ®æˆåŠŸ")
            return df

        except Exception as e:
            print(f"9dbè·å–å¤±è´¥ï¼Œå°è¯•tushare: {e}")

            try:
                # è½¬æ¢ä»£ç æ ¼å¼ï¼ˆ600519 â†’ 600519.SHï¼‰
                ts_code = self._convert_code(symbol)
                df = self.tushare.daily(
                    ts_code=ts_code,
                    start_date=start_date.replace('-', ''),
                    end_date=end_date.replace('-', '')
                )
                print(f"ä»tushareè·å–{symbol}æ•°æ®æˆåŠŸ")
                return df

            except Exception as e2:
                print(f"tushareä¹Ÿå¤±è´¥: {e2}")
                return None

    def _convert_code(self, symbol):
        """è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼"""
        if symbol.startswith('6'):
            return f"{symbol}.SH"
        else:
            return f"{symbol}.SZ"

# ä½¿ç”¨
data_manager = MultiSourceData()
df = data_manager.get_daily_data('600519', '2024-01-01', '2024-01-31')
```

---

## 14.2 æ•°æ®æ¸…æ´—ä¸é¢„å¤„ç†

> ğŸ’¡ **æ•°æ®è´¨é‡å†³å®šç­–ç•¥è´¨é‡**ï¼šè„æ•°æ®ä¼šå¯¼è‡´é”™è¯¯çš„å›æµ‹ç»“æœã€‚ä¸“ä¸šçš„æ•°æ®æ¸…æ´—æ˜¯é‡åŒ–äº¤æ˜“çš„å¿…ä¿®è¯¾ã€‚

### ç¼ºå¤±å€¼å¤„ç†

**å¸¸è§ç¼ºå¤±å€¼æƒ…å†µ**ï¼š

```
1. åœç‰ŒæœŸé—´ï¼šæŸäº›æ—¥æœŸå®Œå…¨æ²¡æœ‰æ•°æ®
2. æ–°è‚¡ä¸Šå¸‚ï¼šå†å²æ•°æ®ä¸è¶³
3. æ•°æ®æºé—®é¢˜ï¼šæŸäº›å­—æ®µç¼ºå¤±
```

**æ£€æŸ¥ç¼ºå¤±å€¼**ï¼š

```python
import pandas as pd

# æ£€æŸ¥ç¼ºå¤±å€¼
print(df.isnull().sum())

# æŸ¥çœ‹ç¼ºå¤±å€¼æ¯”ä¾‹
print(df.isnull().sum() / len(df))

# å¯è§†åŒ–ç¼ºå¤±å€¼
import missingno as msno
msno.matrix(df)
```

**å¤„ç†æ–¹æ³•**ï¼š

```python
# æ–¹æ³•1ï¼šåˆ é™¤å«ç¼ºå¤±å€¼çš„è¡Œ
df_clean = df.dropna()

# æ–¹æ³•2ï¼šå‰å‘å¡«å……ï¼ˆç”¨å‰ä¸€ä¸ªæœ‰æ•ˆå€¼å¡«å……ï¼‰
df['close'] = df['close'].fillna(method='ffill')

# æ–¹æ³•3ï¼šåå‘å¡«å……
df['close'] = df['close'].fillna(method='bfill')

# æ–¹æ³•4ï¼šç”¨å‡å€¼å¡«å……
df['close'] = df['close'].fillna(df['close'].mean())

# æ–¹æ³•5ï¼šæ’å€¼æ³•
df['close'] = df['close'].interpolate(method='linear')

# æ¨èæ–¹æ¡ˆï¼šä»·æ ¼ç”¨å‰å‘å¡«å……ï¼Œæˆäº¤é‡å¡«0
df['close'] = df['close'].fillna(method='ffill')
df['volume'] = df['volume'].fillna(0)
```

### å¼‚å¸¸å€¼æ£€æµ‹

**å¸¸è§å¼‚å¸¸å€¼**ï¼š

```
1. ä»·æ ¼å¼‚å¸¸ï¼šçªç„¶æš´æ¶¨æš´è·Œï¼ˆå¯èƒ½æ˜¯æ•°æ®é”™è¯¯ï¼‰
2. æˆäº¤é‡å¼‚å¸¸ï¼šçªç„¶æ”¾å·¨é‡æˆ–ä¸º0
3. é€»è¾‘é”™è¯¯ï¼šæœ€é«˜ä»·<æœ€ä½ä»·
```

**æ£€æµ‹æ–¹æ³•**ï¼š

```python
def detect_anomalies(df):
    """æ£€æµ‹å¼‚å¸¸å€¼"""

    # 1. æ£€æŸ¥ä»·æ ¼é€»è¾‘
    invalid_ohlc = df[df['high'] < df['low']]
    if len(invalid_ohlc) > 0:
        print(f"å‘ç°{len(invalid_ohlc)}æ¡ä»·æ ¼é€»è¾‘é”™è¯¯")
        print(invalid_ohlc)

    # 2. æ£€æŸ¥æç«¯æ¶¨è·Œå¹…ï¼ˆå•æ—¥æ¶¨è·Œè¶…è¿‡30%å¯èƒ½æ˜¯æ•°æ®é”™è¯¯ï¼‰
    df['pct_change'] = df['close'].pct_change()
    extreme_change = df[abs(df['pct_change']) > 0.3]
    if len(extreme_change) > 0:
        print(f"å‘ç°{len(extreme_change)}æ¡æç«¯æ¶¨è·Œ")
        print(extreme_change[['trade_date', 'close', 'pct_change']])

    # 3. æ£€æŸ¥æˆäº¤é‡ä¸º0
    zero_volume = df[df['volume'] == 0]
    if len(zero_volume) > 0:
        print(f"å‘ç°{len(zero_volume)}æ¡æˆäº¤é‡ä¸º0")

    # 4. ä½¿ç”¨3-sigmaè§„åˆ™æ£€æµ‹ç¦»ç¾¤ç‚¹
    mean = df['close'].mean()
    std = df['close'].std()
    outliers = df[abs(df['close'] - mean) > 3 * std]
    if len(outliers) > 0:
        print(f"å‘ç°{len(outliers)}æ¡ç¦»ç¾¤ç‚¹")

    return df

# ä½¿ç”¨
df_checked = detect_anomalies(df)
```

**å¤„ç†æ–¹æ³•**ï¼š

```python
# æ–¹æ³•1ï¼šåˆ é™¤å¼‚å¸¸å€¼
df_clean = df[abs(df['pct_change']) <= 0.3]

# æ–¹æ³•2ï¼šç”¨ä¸­ä½æ•°æ›¿æ¢
median = df['close'].median()
df.loc[abs(df['pct_change']) > 0.3, 'close'] = median

# æ–¹æ³•3ï¼šç”¨å‰ä¸€æ—¥ä»·æ ¼æ›¿æ¢ï¼ˆå¯¹äºæ˜æ˜¾é”™è¯¯çš„æ•°æ®ï¼‰
def fix_outliers(df):
    """ä¿®æ­£å¼‚å¸¸å€¼"""
    df = df.copy()

    for i in range(1, len(df)):
        # å¦‚æœæ¶¨è·Œå¹…è¶…è¿‡30%ï¼Œç”¨å‰ä¸€æ—¥æ”¶ç›˜ä»·
        if abs(df.loc[i, 'close'] / df.loc[i-1, 'close'] - 1) > 0.3:
            print(f"ä¿®æ­£{df.loc[i, 'trade_date']}çš„å¼‚å¸¸æ•°æ®")
            df.loc[i, 'close'] = df.loc[i-1, 'close']

    return df

df_fixed = fix_outliers(df)
```

### æ•°æ®å¯¹é½

**é—®é¢˜**ï¼šä¸åŒè‚¡ç¥¨çš„äº¤æ˜“æ—¥æœŸå¯èƒ½ä¸ä¸€è‡´ï¼ˆåœç‰Œã€èŠ‚å‡æ—¥ï¼‰

```python
# ç¤ºä¾‹ï¼šä¸‰åªè‚¡ç¥¨æ•°æ®æ—¥æœŸä¸å¯¹é½
stock1 = ['2024-01-02', '2024-01-03', '2024-01-04']  # æ­£å¸¸äº¤æ˜“
stock2 = ['2024-01-02', '2024-01-04']  # 01-03åœç‰Œ
stock3 = ['2024-01-02', '2024-01-03']  # 01-04åœç‰Œ
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
def align_data(stock_list, start_date, end_date):
    """
    å¯¹é½å¤šåªè‚¡ç¥¨æ•°æ®

    å‚æ•°:
        stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
    """
    # 1. è·å–æ‰€æœ‰äº¤æ˜“æ—¥
    trade_calendar = get_trade_calendar(start_date, end_date)

    # 2. ä¸ºæ¯åªè‚¡ç¥¨åˆ›å»ºå®Œæ•´æ—¥æœŸç´¢å¼•
    aligned_data = {}

    for stock in stock_list:
        # è·å–åŸå§‹æ•°æ®
        df = get_stock_data(stock, start_date, end_date)

        # é‡æ–°ç´¢å¼•åˆ°å®Œæ•´äº¤æ˜“æ—¥å†
        df = df.set_index('trade_date')
        df = df.reindex(trade_calendar)

        # å‰å‘å¡«å……ï¼ˆåœç‰ŒæœŸé—´ç”¨å‰ä¸€æ—¥æ•°æ®ï¼‰
        df = df.fillna(method='ffill')

        aligned_data[stock] = df

    return aligned_data

# ä½¿ç”¨
aligned = align_data(['600519', '000858', '600036'], '2024-01-01', '2024-01-31')
```

### å¤æƒå¤„ç†

**ä¸ºä»€ä¹ˆéœ€è¦å¤æƒï¼Ÿ**

```
é€è‚¡ã€é…è‚¡ã€åˆ†çº¢ä¼šå¯¼è‡´ä»·æ ¼è·³ç©ºï¼š
- 10é€10ï¼šè‚¡ä»·ç¬é—´è…°æ–©
- åˆ†çº¢10å…ƒï¼šè‚¡ä»·ä¸‹è·Œ10å…ƒ

ä¸å¤æƒçš„æ•°æ®æ— æ³•å‡†ç¡®è®¡ç®—æ”¶ç›Šç‡ï¼
```

**å¤æƒç±»å‹**ï¼š

```
å‰å¤æƒï¼ˆqfqï¼‰ï¼š
- ä¿æŒæœ€æ–°ä»·ä¸å˜
- è°ƒæ•´å†å²ä»·æ ¼
- é€‚åˆï¼šçœ‹å½“å‰å¸‚ä»·

åå¤æƒï¼ˆhfqï¼‰ï¼šâ­ æ¨è
- ä¿æŒå†å²ä»·ä¸å˜
- è°ƒæ•´æœ€æ–°ä»·æ ¼
- é€‚åˆï¼šå›æµ‹ï¼ˆè®¡ç®—çœŸå®æ”¶ç›Šç‡ï¼‰

ä¸å¤æƒï¼š
- ä¿æŒåŸå§‹ä»·æ ¼
- é€‚åˆï¼šæ—¥å†…äº¤æ˜“ã€å®ç›˜ä¸‹å•
```

**ç¤ºä¾‹**ï¼š

```python
# è·å–ä¸åŒå¤æƒæ–¹å¼çš„æ•°æ®
df_no_adjust = db.stock.daily(symbol='600519', start_date='2020-01-01', adjust=None)
df_qfq = db.stock.daily(symbol='600519', start_date='2020-01-01', adjust='qfq')
df_hfq = db.stock.daily(symbol='600519', start_date='2020-01-01', adjust='hfq')

# å¯¹æ¯”
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(df_no_adjust['trade_date'], df_no_adjust['close'], label='ä¸å¤æƒ')
plt.plot(df_qfq['trade_date'], df_qfq['close'], label='å‰å¤æƒ')
plt.plot(df_hfq['trade_date'], df_hfq['close'], label='åå¤æƒ')
plt.legend()
plt.title('ä¸åŒå¤æƒæ–¹å¼å¯¹æ¯”')
plt.show()
```

**å›æµ‹å¿…ç”¨åå¤æƒ**ï¼š

```python
# è®¡ç®—çœŸå®æ”¶ç›Šç‡ï¼ˆå¿…é¡»ç”¨åå¤æƒï¼‰
df_hfq = df_hfq.sort_values('trade_date')
df_hfq['returns'] = df_hfq['close'].pct_change()

# ç´¯è®¡æ”¶ç›Š
df_hfq['cumulative_returns'] = (1 + df_hfq['returns']).cumprod() - 1

print(f"æ€»æ”¶ç›Šç‡: {df_hfq['cumulative_returns'].iloc[-1]*100:.2f}%")
```

### åœç‰Œæ•°æ®å¤„ç†

**åœç‰Œçš„å½±å“**ï¼š

```
1. ä»·æ ¼æ•°æ®ç¼ºå¤±
2. æ— æ³•ä¹°å…¥/å–å‡º
3. å›æµ‹æ—¶éœ€è¦ç‰¹æ®Šå¤„ç†
```

**å¤„ç†æ–¹æ³•**ï¼š

```python
def handle_suspension(df):
    """å¤„ç†åœç‰Œæ•°æ®"""

    # 1. æ ‡è®°åœç‰Œæ—¥æœŸï¼ˆæˆäº¤é‡ä¸º0ï¼‰
    df['is_suspended'] = (df['volume'] == 0)

    # 2. åœç‰ŒæœŸé—´ä»·æ ¼ç”¨å‰ä¸€æ—¥å¡«å……
    df['close'] = df['close'].fillna(method='ffill')

    # 3. æ·»åŠ åœç‰Œå¤©æ•°ç»Ÿè®¡
    df['suspension_days'] = df['is_suspended'].groupby(
        (df['is_suspended'] != df['is_suspended'].shift()).cumsum()
    ).cumsum()

    return df

df = handle_suspension(df)

# å›æµ‹æ—¶çš„å¤„ç†
def backtest_with_suspension(df):
    """å›æµ‹æ—¶è€ƒè™‘åœç‰Œ"""

    for i in range(len(df)):
        if df.loc[i, 'is_suspended']:
            # åœç‰Œæ—¥ä¸å…è®¸äº¤æ˜“
            print(f"{df.loc[i, 'trade_date']}: åœç‰Œï¼Œè·³è¿‡")
            continue

        # æ­£å¸¸äº¤æ˜“é€»è¾‘
        # ...
```

---

## 14.3 æ•°æ®å­˜å‚¨æ–¹æ¡ˆ

> ğŸ’¡ **ä¸ºä»€ä¹ˆéœ€è¦æœ¬åœ°å­˜å‚¨ï¼Ÿ**
> 1. é¿å…é‡å¤ä¸‹è½½ï¼ŒèŠ‚çœæ—¶é—´
> 2. å‡å°‘APIè°ƒç”¨æ¬¡æ•°
> 3. ç¦»çº¿ä¹Ÿèƒ½å›æµ‹

### CSVæ–‡ä»¶å­˜å‚¨

**æœ€ç®€å•çš„æ–¹æ¡ˆ**ï¼š

```python
import pandas as pd

# ä¿å­˜
df.to_csv('600519_daily.csv', index=False, encoding='utf-8-sig')

# è¯»å–
df = pd.read_csv('600519_daily.csv')

# æ‰¹é‡ä¿å­˜å¤šåªè‚¡ç¥¨
for code in stock_list:
    df = get_stock_data(code)
    df.to_csv(f'data/{code}.csv', index=False)
```

**ä¼˜ç¼ºç‚¹**ï¼š

```
âœ… ä¼˜ç‚¹
- ç®€å•æ˜“ç”¨
- å¯è¯»æ€§å¥½
- ä»»ä½•å·¥å…·éƒ½èƒ½æ‰“å¼€

âŒ ç¼ºç‚¹
- æ–‡ä»¶å¤šæ—¶ç®¡ç†æ··ä¹±
- è¯»å–é€Ÿåº¦æ…¢ï¼ˆå¤§æ•°æ®é‡æ—¶ï¼‰
- å ç”¨ç©ºé—´å¤§
```

---

### HDF5é«˜æ•ˆå­˜å‚¨ â­

**æ¨èæ–¹æ¡ˆ**ï¼šé€‚åˆå­˜å‚¨å¤§é‡æ—¶é—´åºåˆ—æ•°æ®

```python
import pandas as pd

# ä¿å­˜åˆ°HDF5
df.to_hdf('stock_data.h5', key='600519', mode='w')

# æ‰¹é‡ä¿å­˜
with pd.HDFStore('all_stocks.h5', mode='w') as store:
    for code in stock_list:
        df = get_stock_data(code)
        store[code] = df

# è¯»å–
df = pd.read_hdf('stock_data.h5', key='600519')

# è¯»å–å¤šåªè‚¡ç¥¨
with pd.HDFStore('all_stocks.h5', mode='r') as store:
    df_600519 = store['600519']
    df_000858 = store['000858']

# æŸ¥çœ‹HDF5æ–‡ä»¶å†…å®¹
with pd.HDFStore('all_stocks.h5', mode='r') as store:
    print(store.keys())  # æŸ¥çœ‹æ‰€æœ‰key
```

**ä¼˜ç¼ºç‚¹**ï¼š

```
âœ… ä¼˜ç‚¹
- è¯»å†™é€Ÿåº¦å¿«ï¼ˆæ¯”CSVå¿«10å€+ï¼‰
- å‹ç¼©å­˜å‚¨ï¼ŒèŠ‚çœç©ºé—´
- æ”¯æŒéšæœºè®¿é—®
- å•æ–‡ä»¶ç®¡ç†ï¼Œä¸ä¼šæ–‡ä»¶æ³›æ»¥

âŒ ç¼ºç‚¹
- ä¸èƒ½ç›´æ¥æ‰“å¼€æŸ¥çœ‹
- éœ€è¦pandasè¯»å–
```

---

### æ•°æ®åº“å­˜å‚¨

**é€‚åˆå¤§è§„æ¨¡æ•°æ®**ï¼š

#### MySQLå­˜å‚¨

```python
import pymysql
from sqlalchemy import create_engine
import pandas as pd

# åˆ›å»ºæ•°æ®åº“è¿æ¥
engine = create_engine('mysql+pymysql://ç”¨æˆ·å:å¯†ç @localhost:3306/stock_db')

# ä¿å­˜åˆ°MySQL
df.to_sql('daily_600519', con=engine, if_exists='replace', index=False)

# è¯»å–
df = pd.read_sql('SELECT * FROM daily_600519', con=engine)

# æŸ¥è¯¢
df = pd.read_sql("""
    SELECT * FROM daily_600519
    WHERE trade_date >= '2024-01-01'
    AND close > 1700
""", con=engine)
```

#### ClickHouseå­˜å‚¨ï¼ˆé«˜æ€§èƒ½ï¼‰

```python
from clickhouse_driver import Client

# è¿æ¥ClickHouse
client = Client(host='localhost')

# åˆ›å»ºè¡¨
client.execute("""
    CREATE TABLE IF NOT EXISTS stock_daily (
        symbol String,
        trade_date Date,
        open Float64,
        high Float64,
        low Float64,
        close Float64,
        volume UInt64
    ) ENGINE = MergeTree()
    ORDER BY (symbol, trade_date)
""")

# æ‰¹é‡æ’å…¥
data = df.to_dict('records')
client.execute('INSERT INTO stock_daily VALUES', data)

# æŸ¥è¯¢
result = client.execute("""
    SELECT * FROM stock_daily
    WHERE symbol = '600519'
    AND trade_date >= '2024-01-01'
""")
```

---

### Redisç¼“å­˜åº”ç”¨

**é€‚åˆçƒ­ç‚¹æ•°æ®ç¼“å­˜**ï¼š

```python
import redis
import json
import pandas as pd

# è¿æ¥Redis
r = redis.Redis(host='localhost', port=6379, db=0)

# ç¼“å­˜æ•°æ®
def cache_stock_data(symbol, df):
    """å°†æ•°æ®ç¼“å­˜åˆ°Redis"""
    key = f"stock:{symbol}:daily"
    value = df.to_json()
    r.setex(key, 3600, value)  # ç¼“å­˜1å°æ—¶

# è¯»å–ç¼“å­˜
def get_cached_data(symbol):
    """ä»Redisè¯»å–ç¼“å­˜"""
    key = f"stock:{symbol}:daily"
    value = r.get(key)

    if value:
        return pd.read_json(value)
    else:
        return None

# ä½¿ç”¨
cached = get_cached_data('600519')
if cached is not None:
    print("ä½¿ç”¨ç¼“å­˜æ•°æ®")
    df = cached
else:
    print("ç¼“å­˜æœªå‘½ä¸­ï¼Œé‡æ–°è·å–")
    df = get_stock_data('600519')
    cache_stock_data('600519', df)
```

---

### å®Œæ•´æ•°æ®ç®¡ç†æ–¹æ¡ˆ

**æ¨èæ¶æ„**ï¼š

```python
class DataManager:
    """æ•°æ®ç®¡ç†å™¨ï¼ˆæœ¬åœ°ç¼“å­˜ + è¿œç¨‹æ•°æ®æºï¼‰"""

    def __init__(self, cache_dir='./data'):
        self.cache_dir = cache_dir
        self.db = NineDB()  # è¿œç¨‹æ•°æ®æº

    def get_daily(self, symbol, start_date, end_date, use_cache=True):
        """
        è·å–æ—¥çº¿æ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼‰
        """
        cache_file = f"{self.cache_dir}/{symbol}.h5"

        # 1. å°è¯•ä»ç¼“å­˜è¯»å–
        if use_cache and os.path.exists(cache_file):
            print(f"ä»ç¼“å­˜è¯»å–{symbol}")
            df = pd.read_hdf(cache_file, key='daily')

            # æ£€æŸ¥æ—¥æœŸèŒƒå›´æ˜¯å¦æ»¡è¶³
            if df['trade_date'].min() <= start_date and df['trade_date'].max() >= end_date:
                return df[(df['trade_date'] >= start_date) & (df['trade_date'] <= end_date)]

        # 2. ç¼“å­˜ä¸å­˜åœ¨æˆ–ä¸æ»¡è¶³ï¼Œä»è¿œç¨‹è·å–
        print(f"ä»è¿œç¨‹è·å–{symbol}")
        df = self.db.stock.daily(symbol=symbol, start_date=start_date, end_date=end_date)

        # 3. æ›´æ–°ç¼“å­˜
        df.to_hdf(cache_file, key='daily', mode='w')

        return df

    def update_cache(self, symbol):
        """æ›´æ–°ç¼“å­˜åˆ°æœ€æ–°æ—¥æœŸ"""
        cache_file = f"{self.cache_dir}/{symbol}.h5"

        if os.path.exists(cache_file):
            # è¯»å–ç°æœ‰æ•°æ®
            df_old = pd.read_hdf(cache_file, key='daily')
            last_date = df_old['trade_date'].max()

            # è·å–å¢é‡æ•°æ®
            df_new = self.db.stock.daily(symbol=symbol, start_date=last_date)

            # åˆå¹¶
            df = pd.concat([df_old, df_new]).drop_duplicates('trade_date')
        else:
            # é¦–æ¬¡è·å–
            df = self.db.stock.daily(symbol=symbol, start_date='2020-01-01')

        # ä¿å­˜
        df.to_hdf(cache_file, key='daily', mode='w')
        print(f"{symbol}ç¼“å­˜å·²æ›´æ–°")

# ä½¿ç”¨
dm = DataManager()

# è·å–æ•°æ®ï¼ˆè‡ªåŠ¨ä½¿ç”¨ç¼“å­˜ï¼‰
df = dm.get_daily('600519', '2024-01-01', '2024-12-31')

# å®šæœŸæ›´æ–°ç¼“å­˜
dm.update_cache('600519')
```

---

## æœ¬ç« æ€»ç»“

**ä½ å·²ç»æŒæ¡äº†**ï¼š

```
âœ… ä¸‰å¤§æ•°æ®æºä½¿ç”¨
   - Tushare Proï¼ˆå…è´¹ï¼Œé€‚åˆå…¥é—¨ï¼‰
   - 9dbæ•°æ®å¹³å°ï¼ˆä»˜è´¹ï¼Œé«˜è´¨é‡ï¼‰â­
   - AKShareï¼ˆå…è´¹ï¼Œå¿«é€ŸéªŒè¯ï¼‰

âœ… æ•°æ®æ¸…æ´—æŠ€æœ¯
   - ç¼ºå¤±å€¼å¤„ç†
   - å¼‚å¸¸å€¼æ£€æµ‹
   - æ•°æ®å¯¹é½
   - å¤æƒå¤„ç†
   - åœç‰Œå¤„ç†

âœ… æ•°æ®å­˜å‚¨æ–¹æ¡ˆ
   - CSVï¼ˆç®€å•ï¼‰
   - HDF5ï¼ˆæ¨èï¼‰â­
   - æ•°æ®åº“ï¼ˆå¤§è§„æ¨¡ï¼‰
   - Redisç¼“å­˜ï¼ˆçƒ­ç‚¹æ•°æ®ï¼‰
```

**ä¸‹ä¸€æ­¥**ï¼š

```
1. é€‰æ‹©ä¸€ä¸ªæ•°æ®æºï¼Œè·å–çœŸå®è‚¡ç¥¨æ•°æ®
2. å®è·µæ•°æ®æ¸…æ´—æµç¨‹
3. æ­å»ºè‡ªå·±çš„æ•°æ®ç®¡ç†ç³»ç»Ÿ
4. å‡†å¤‡è¿›å…¥ç¬¬åäº”ç« ï¼šç®€å•ç­–ç•¥å®ç°
```

---

## ç»ƒä¹ é¢˜

**åŸºç¡€ç»ƒä¹ **ï¼š

```python
# ç»ƒä¹ 1ï¼šä½¿ç”¨Tushareè·å–å·¥å•†é“¶è¡Œï¼ˆ601398ï¼‰2024å¹´çš„æ—¥çº¿æ•°æ®
# ä½ çš„ä»£ç ï¼š


# ç»ƒä¹ 2ï¼šæ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦æœ‰ç¼ºå¤±å€¼ï¼Œå¹¶è¿›è¡Œå¤„ç†
# ä½ çš„ä»£ç ï¼š


# ç»ƒä¹ 3ï¼šè®¡ç®—è¯¥è‚¡ç¥¨çš„5æ—¥ã€10æ—¥ã€20æ—¥ç§»åŠ¨å¹³å‡çº¿
# ä½ çš„ä»£ç ï¼š


# ç»ƒä¹ 4ï¼šå°†æ•°æ®ä¿å­˜åˆ°æœ¬åœ°CSVæ–‡ä»¶
# ä½ çš„ä»£ç ï¼š
```

**è¿›é˜¶ç»ƒä¹ **ï¼š

```python
# ç»ƒä¹ 5ï¼šç¼–å†™å‡½æ•°ï¼Œæ‰¹é‡è·å–æ²ªæ·±300æˆåˆ†è‚¡æ•°æ®
def get_hs300_data(start_date, end_date):
    # ä½ çš„ä»£ç ï¼š
    pass


# ç»ƒä¹ 6ï¼šç¼–å†™DataManagerç±»ï¼Œå®ç°æ•°æ®ç¼“å­˜æœºåˆ¶
class DataManager:
    def __init__(self, cache_dir):
        # ä½ çš„ä»£ç ï¼š
        pass

    def get_data(self, symbol, start_date, end_date):
        # ä½ çš„ä»£ç ï¼š
        pass


# ç»ƒä¹ 7ï¼šæ£€æµ‹å¹¶å¤„ç†æ•°æ®ä¸­çš„å¼‚å¸¸å€¼
def clean_data(df):
    # ä½ çš„ä»£ç ï¼š
    pass
```

---

## å¸¸è§é—®é¢˜FAQ

**Q1: å…è´¹æ•°æ®å¤Ÿç”¨å—ï¼Ÿ**

```
å­¦ä¹ é˜¶æ®µï¼šå¤Ÿç”¨
- Tushareæ—¥çº¿æ•°æ®å…è´¹
- AKShareå®Œå…¨å…è´¹

å®ç›˜é˜¶æ®µï¼šå»ºè®®ä»˜è´¹
- æ•°æ®è´¨é‡æ›´ç¨³å®š
- åˆ†é’Ÿçº§æ•°æ®
- æ›´å…¨é¢çš„è´¢åŠ¡æ•°æ®

æ¨èï¼šå­¦ä¹ ç”¨å…è´¹ï¼Œå®ç›˜ç”¨9db
```

**Q2: æ•°æ®è¦å­˜å¤šå°‘å¹´ï¼Ÿ**

```
å»ºè®®ï¼šè‡³å°‘5å¹´

åŸå› ï¼š
- å›æµ‹éœ€è¦è¶³å¤Ÿé•¿çš„å†å²
- éªŒè¯ç­–ç•¥åœ¨ä¸åŒå¸‚åœºç¯å¢ƒä¸‹çš„è¡¨ç°
- è®¡ç®—é•¿æœŸæŠ€æœ¯æŒ‡æ ‡ï¼ˆå¦‚200æ—¥å‡çº¿ï¼‰

ä½†æ³¨æ„ï¼š
- å¸‚åœºç¯å¢ƒå˜åŒ–ï¼Œå¤ªä¹…è¿œçš„æ•°æ®å¯èƒ½å¤±æ•ˆ
- 10å¹´ä»¥ä¸Šçš„æ•°æ®å‚è€ƒä»·å€¼é™ä½
```

**Q3: åå¤æƒå’Œå‰å¤æƒåˆ°åº•ç”¨å“ªä¸ªï¼Ÿ**

```
å›æµ‹ï¼šå¿…é¡»ç”¨åå¤æƒï¼ˆhfqï¼‰
- è®¡ç®—çœŸå®æ”¶ç›Šç‡
- åæ˜ çœŸå®æŠ•èµ„å›æŠ¥

å®ç›˜ï¼šç”¨ä¸å¤æƒæˆ–å‰å¤æƒ
- ä¸‹å•ç”¨å®é™…ä»·æ ¼
- å‰å¤æƒæ–¹ä¾¿çœ‹å½“å‰å¸‚ä»·

è®°ä½ï¼šå›æµ‹ç”¨åå¤æƒï¼
```

**Q4: æ•°æ®å­˜å‚¨ç”¨å“ªç§æ–¹æ¡ˆï¼Ÿ**

```
å°è§„æ¨¡ï¼ˆ<100åªè‚¡ç¥¨ï¼‰ï¼šHDF5 â­
ä¸­è§„æ¨¡ï¼ˆ100-1000åªï¼‰ï¼šHDF5 æˆ– MySQL
å¤§è§„æ¨¡ï¼ˆ>1000åªï¼‰ï¼šClickHouse + HDF5

ä¸ªäººé‡åŒ–ï¼šHDF5è¶³å¤Ÿ
```

**Q5: å¦‚ä½•éªŒè¯æ•°æ®è´¨é‡ï¼Ÿ**

```
1. äº¤å‰éªŒè¯
   - å¯¹æ¯”å¤šä¸ªæ•°æ®æº
   - çœ‹æ˜¯å¦ä¸€è‡´

2. é€»è¾‘æ£€æŸ¥
   - æœ€é«˜ä»· >= æœ€ä½ä»·
   - æˆäº¤é‡ >= 0
   - æ¶¨è·Œåœé™åˆ¶

3. å¯¹æ¯”å…¬å¼€æ•°æ®
   - ä¸ä¸œæ–¹è´¢å¯Œã€åŒèŠ±é¡ºå¯¹æ¯”
   - é‡ç‚¹å…³æ³¨é‡è¦æ—¥æœŸï¼ˆåˆ†çº¢ã€é€è‚¡ï¼‰
```

**Q6: Tushareç§¯åˆ†ä¸å¤Ÿæ€ä¹ˆåŠï¼Ÿ**

```
1. æ¯æ—¥ç­¾åˆ°ï¼ˆ+1ç§¯åˆ†ï¼‰
2. é‚€è¯·å¥½å‹ï¼ˆ+100ç§¯åˆ†ï¼‰
3. å……å€¼è´­ä¹°
4. é™ä½éœ€æ±‚ï¼ˆåªç”¨æ—¥çº¿æ•°æ®ï¼‰
5. æ¢ç”¨9dbæˆ–AKShare
```

---

## å­¦ä¹ èµ„æºæ¨è

**æ•°æ®æºå®˜æ–¹æ–‡æ¡£**ï¼š

```
Tushare Pro: https://tushare.pro/document/2
9db: https://www.9db.com/docs
AKShare: https://akshare.akfamily.xyz/
```

**Pandaså®˜æ–¹æ–‡æ¡£**ï¼š

```
https://pandas.pydata.org/docs/
```

**ç›¸å…³ä¹¦ç±**ï¼š

```
ã€Šåˆ©ç”¨Pythonè¿›è¡Œæ•°æ®åˆ†æã€‹- Wes McKinney
ã€ŠPythoné‡‘èå¤§æ•°æ®åˆ†æã€‹- Yves Hilpisch
```

---

**æ­å–œï¼ä½ å·²ç»æŒæ¡é‡åŒ–äº¤æ˜“çš„æ•°æ®åŸºç¡€ã€‚**

**ä¸‹ä¸€ç« é¢„å‘Š**ï¼šç¬¬åäº”ç« ã€Šç®€å•ç­–ç•¥å®ç°ã€‹ï¼Œæˆ‘ä»¬å°†ï¼š
- å®ç°ç¬¬ä¸€ä¸ªå®Œæ•´çš„åŒå‡çº¿ç­–ç•¥
- å­¦ä¹ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
- è¿›è¡Œç®€å•å›æµ‹
- åˆ†æç­–ç•¥è¡¨ç°

**æ•°æ®å·²å¤‡é½ï¼Œç­–ç•¥å¼€å‘æ­£å¼å¼€å§‹ï¼** ğŸš€
